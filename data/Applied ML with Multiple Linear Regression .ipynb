{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this allows us to read in the data and work with dataframes and work with arrays, \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#import our plotting libraries\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#read in the entire house dataset,\n",
    "house_df = pd.read_csv('house_prices_1/train.csv')\n",
    "\n",
    "#outputs the no of rows and columns in the dataset,\n",
    "print('=> The number of rows and columns in our dataset is (rows, columns):')\n",
    "print(house_df.shape,'\\n')\n",
    "\n",
    "#outputs the columns header,\n",
    "print('=> A sample of the column headers in the dataset are:')\n",
    "print(house_df.iloc[:,2:8].columns.values)\n",
    "\n",
    "#outputs the summary statistics and info,\n",
    "print('\\n=> These are the summary statistics for a sample of the columns:\\n')\n",
    "print(house_df.iloc[:,71:].describe())\n",
    "print('\\n=> These are the info for a sample of the columns:\\n')\n",
    "print(house_df.iloc[:,71:80].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = house_df[['SalePrice', 'PoolArea','MoSold']]\n",
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "#function for plotting stripplots given a dataframe\n",
    "def stripplot_these(df):\n",
    "    for idx, name in enumerate(df.columns):\n",
    "        n = idx + 1\n",
    "        plt.subplot(1,3,n)\n",
    "        sns.stripplot(x=name, data=df, jitter=0.15, orient= 'v', alpha=.4)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "stripplot_these(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting histogram of values with density values and outlier threshold \n",
    "mu = house_df.SalePrice.mean()\n",
    "sd = house_df.SalePrice.std()\n",
    "li = mu + 3 * sd\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Density Histogram of Sale Price')\n",
    "plt.hist(house_df.SalePrice, bins=75,density=True,color='orange')\n",
    "plt.axvline(li, color='grey', linestyle='dashed', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of column names to keep\n",
    "col_names = ['SalePrice','OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea']\n",
    "\n",
    "#creating new filtered dataframe\n",
    "new_df =  house_df[col_names]\n",
    "\n",
    "#print the new shape of the data,\n",
    "print('The current number of rows and columns is:\\n')\n",
    "print(new_df.shape)\n",
    "print('\\nWe have reduce the number of variables from 81 to', new_df.shape[1],'\\n')\n",
    "\n",
    "#checking summary statistics and info of new dataframe\n",
    "print(new_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the dataframe to include just the IV's (features) and another with just the DV's (target)\n",
    "features = new_df.loc[:,new_df.columns != 'SalePrice']\n",
    "targets = new_df.loc[:,new_df.columns == 'SalePrice']\n",
    "\n",
    "#creating pairwise correlation of columns using Pearson's R,\n",
    "corr = features.corr(method='pearson') \n",
    "\n",
    "#plotting the correlation coefficients on a seasborn heatmap matrix\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "sns.heatmap(corr, annot=True, xticklabels=corr.columns, \n",
    "            yticklabels=corr.columns, ax=ax, linewidths=.5, \n",
    "            vmin = -1, vmax=1, center=0)\n",
    "\n",
    "plt.title('Correlation HeatMap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing our function for splitting the data and an additional cross validation function,\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "#splitting our dataset randomly with the test data containing 10% of the data,\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,targets, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)\n",
    "\n",
    "#view number of training and testing data\n",
    "print('Our training prediction variable contains :',len(y_train) ,'rows')\n",
    "print('Our training independent variable contains :',len(X_train) ,'rows')\n",
    "print('Our testing prediction variable contains :',len(y_test) ,'rows')\n",
    "print('Our testing independent variable contains :',len(X_test) ,'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allows us access to Scikit-learn linear regression model,\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Instantiate the regression model and setting parameters if any,\n",
    "reg_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the training data to the model,\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "#outputs the coefficients\n",
    "print('Intercept :', reg_model.intercept_[0], '\\n')\n",
    "print(pd.DataFrame({'features':X_train.columns,'coeficients':reg_model.coef_[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs the training and testing scores\n",
    "print(\"Training set score: {:.2f}\".format(reg_model.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import math\n",
    "\n",
    "cv_reg_model = LinearRegression()\n",
    "cv_scores = cross_val_score(cv_reg_model, features, targets,cv=10, scoring='r2')\n",
    "\n",
    "#outputs the scores\n",
    "print('Cross Validation scores: {}'.format(cv_scores))\n",
    "print(\"\\nAverage 10-Fold CV Score: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction values using testing set\n",
    "y_pred = reg_model.predict(X_test)\n",
    "\n",
    "#printing sample of predictions\n",
    "print('Sample predictions are:\\n', y_pred[:5].flatten())\n",
    "\n",
    "y_pred_a = pd.DataFrame(y_pred)\n",
    "y_test_a = y_test.reset_index(drop=True, inplace=False)\n",
    "pred_act_df = pd.concat([y_test_a,y_pred_a], axis=1).sort_values(1,axis=1).reset_index(drop=True)\n",
    "\n",
    "#output samples of our predicted values\n",
    "plt.figure(figsize=(6, 6))\n",
    "maxlimit = pred_act_df['SalePrice'].max()\n",
    "plt.xlim(-1, maxlimit)\n",
    "plt.ylim(-1, maxlimit)\n",
    "plt.scatter(pred_act_df[0], pred_act_df['SalePrice'], s=10)\n",
    "plt.xlabel('Predicted Sale Price')\n",
    "plt.ylabel('Actual Sale Price')\n",
    "plt.plot([-1,maxlimit], [-1,maxlimit], ls=\"--\", c=\".3\")\n",
    "plt.title('Actual vs Predicted Sale Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats model library allows us to run OLS directly,\n",
    "import statsmodels.api as sm \n",
    "\n",
    "#re-run OLS model as sm_model using training and testing dataset,\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "sm_train_model = sm.OLS(y_train, X_train_sm).fit()\n",
    "print('Training set adj r2: {}'.format(sm_train_model.rsquared_adj))\n",
    "\n",
    "#run CV again and loop through results applying adjusted r2 formula. Output the results\n",
    "cv_scores_r2 = cross_val_score(cv_reg_model, features, targets,cv=10, scoring='r2')\n",
    "cv_scores_adj = []\n",
    "n = len(features)\n",
    "k = len(features.columns)\n",
    "for r in cv_scores_r2:\n",
    "    adj_r2 = 1-(((1-r)*(n-1))/(n-k-1))\n",
    "    cv_scores_adj.append(adj_r2)\n",
    "print('Average 10-Fold CV adj r2: {}'.format(np.mean(cv_scores_adj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for calculating MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred_test = reg_model.predict(X_test)\n",
    "y_pred_train = reg_model.predict(X_train)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "print(\"Root Mean Squared Error of Training Set: {}\".format(rmse_train))\n",
    "print(\"Root Mean Squared Error of Testing Set: {}\".format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets us use the stats model ols model\n",
    "import statsmodels.api as sm \n",
    "\n",
    "#training the OLS algorithm and outputting the summary statistics\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "sm_model = sm.OLS(y_train, X_train_sm).fit()\n",
    "print(sm_model.summary())\n",
    "print(sm_model.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the residuals\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "residuals = y_test.SalePrice - y_pred[0]\n",
    "\n",
    "#plotting Residual and Probabililty graph\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axhline(0, color=\"blue\")\n",
    "plt.title('Plot of Residuals')\n",
    "plt.scatter(residuals.index,residuals, s=20)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Probability Plot')\n",
    "stats.probplot(residuals, dist='norm',plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
